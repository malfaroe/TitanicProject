{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# import all libraries and dependencies for data visualization\n",
    "pd.options.display.float_format='{:.4f}'.format\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "pd.set_option('display.max_columns', 350)\n",
    "pd.set_option('display.max_colwidth', -1) \n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "sns.set(style='darkgrid')\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "\n",
    "# import all libraries and dependencies for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import RobustScaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression, OrthogonalMatchingPursuit, Lasso, LassoLarsIC, ElasticNet, ElasticNetCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression, SelectKBest, RFECV, SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, kurtosis, skew\n",
    "\n",
    "# Import specific libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats import diagnostic as diag\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler, PolynomialFeatures, StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression, SelectKBest, RFECV, SelectFromModel\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression, OrthogonalMatchingPursuit, Lasso, LassoLarsIC, ElasticNet, ElasticNetCV\n",
    "from sklearn.linear_model import SGDRegressor, PassiveAggressiveRegressor, HuberRegressor, BayesianRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "import mlxtend\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "import lightgbm as lgb\n",
    "# Models\n",
    "import mlxtend\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from patsy import dmatrices\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import skew, norm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm, probplot, boxcox\n",
    "from scipy.special import boxcox1p\n",
    "from patsy import dmatrices\n",
    "\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "#For baseline estimations\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#My own libraries :)\n",
    "\n",
    "from house_utils import data_summary, features_profile, plot_feats\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train2\n",
    "%store -r test2\n",
    "\n",
    "train = train2.copy()\n",
    "test = test2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##PODAR DATASETS DE ACUERDO A FEATURE IMPORTANCE LOOP\n",
    "#del_cols = [ \"Embarked\", \"Parch\", \"SibSp\", \"Ticket_freq\", \"FamilySize\"]\n",
    "del_cols = [  \"Ticket_freq\", \"FamilySize\"]\n",
    "\n",
    "\n",
    "\n",
    "train.drop(del_cols, axis = 1, inplace = True)\n",
    "test.drop(del_cols, axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data\n",
    "\n",
    "##USAMOS TODO EL TRAIN PARA ENTRENAR LOS ALGORITMOS\n",
    "y_train = train.pop(\"Survived\")\n",
    "X_train = train\n",
    "\n",
    "# X_train,  X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SVC\\nDecision Tree\\nAdaBoost\\nRandom Forest\\nExtra Trees\\nGradient Boosting\\nMultiple layer perceprton (neural network)\\nKNN\\nLogistic regression\\nLinear Discriminant Analysis'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Simple modeling: we compare 10 popular classifiers and evaluate their mean accuracy (using KFold stratified cross val)\n",
    "\n",
    "\"\"\"SVC\n",
    "Decision Tree\n",
    "AdaBoost\n",
    "Random Forest\n",
    "Extra Trees\n",
    "Gradient Boosting\n",
    "Multiple layer perceprton (neural network)\n",
    "KNN\n",
    "Logistic regression\n",
    "Linear Discriminant Analysis\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crossvalidate the models with KFold\n",
    "kfold = StratifiedKFold(n_splits= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. We train and calculate the mean accuracy of each algorithm\n",
    "\n",
    "#Creamos una lista con todos los clasificadores\n",
    "random_state = 2\n",
    "classifiers = []\n",
    "\n",
    "classifiers.append(SVC(random_state= random_state))\n",
    "classifiers.append(DecisionTreeClassifier(random_state= random_state))\n",
    "classifiers. append(AdaBoostClassifier(DecisionTreeClassifier(random_state= random_state), random_state= random_state\n",
    "                                      , learning_rate= 0.1))\n",
    "classifiers.append(RandomForestClassifier(random_state= random_state))\n",
    "classifiers.append(ExtraTreesClassifier(random_state= random_state))\n",
    "classifiers.append(GradientBoostingClassifier(random_state= random_state))\n",
    "classifiers.append(MLPClassifier(random_state= random_state))\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(LogisticRegression(random_state= random_state))\n",
    "classifiers.append(LinearDiscriminantAnalysis())\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "#Calculamos los crossvals\n",
    "for classifier in classifiers:\n",
    "    cv_results.append(cross_val_score(classifier, X_train, y = y_train, scoring = \"accuracy\",\n",
    "                     cv = kfold, n_jobs = 4))\n",
    "    \n",
    "#Calculamos los means de cada resultados\n",
    "\n",
    "cv_means = []\n",
    "cv_std = []\n",
    "\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "\n",
    "\n",
    "#Creamos un dataframe con los resultados\n",
    "\n",
    "cv_res = pd.DataFrame({\"CrossValMeans\": cv_means, \"CrossValErrors (std)\": cv_std, \n",
    "                      \"Algorithm\": [\"SVC\",\"DecisionTree\",\"AdaBoost\",\n",
    "\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\n",
    "                                    \"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CrossValMeans</th>\n",
       "      <th>CrossValErrors (std)</th>\n",
       "      <th>Algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8329</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>GradientBoosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8060</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8036</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8015</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>ExtraTrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8003</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>DecisionTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7968</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7779</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7712</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>KNeighboors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7028</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>MultipleLayerPerceptron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CrossValMeans  CrossValErrors (std)                   Algorithm\n",
       "5 0.8329         0.0394                 GradientBoosting          \n",
       "3 0.8160         0.0277                 RandomForest              \n",
       "2 0.8060         0.0419                 AdaBoost                  \n",
       "8 0.8036         0.0234                 LogisticRegression        \n",
       "4 0.8015         0.0363                 ExtraTrees                \n",
       "1 0.8003         0.0312                 DecisionTree              \n",
       "9 0.7968         0.0274                 LinearDiscriminantAnalysis\n",
       "0 0.7779         0.0411                 SVC                       \n",
       "7 0.7712         0.0436                 KNeighboors               \n",
       "6 0.7028         0.0485                 MultipleLayerPerceptron   "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking performance of algoritms...\n",
    "cv_res.sort_values(by = \"CrossValMeans\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We can also plot the results...\n",
    "g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\n",
    "g.set_xlabel(\"Mean Accuracy\")\n",
    "g = g.set_title(\"Cross validation scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We choose the 5 best performing algorithms for ensambling and we will see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8406285072951739"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Hyperparameter  tuning for getting the best models\n",
    "\n",
    "#RANDOM FOREST\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "#Search grid for optimal parameters\n",
    "rf_param_grid = {\"max_depth\": [None], \"max_features\": [1,3,10],\n",
    "                \"min_samples_split\": [2,3,10],\n",
    "                \"min_samples_leaf\": [1,3,10],\n",
    "                \"bootstrap\": [False],\n",
    "                \"n_estimators\": [100,300],\n",
    "                \"criterion\": [\"gini\"]}\n",
    "\n",
    "gsRFC = GridSearchCV(RFC, param_grid = rf_param_grid, cv = kfold, scoring = \"accuracy\",\n",
    "                    n_jobs = 1, verbose = 1)\n",
    "\n",
    "gsRFC.fit(X_train, y_train)\n",
    "    \n",
    "RFC_best = gsRFC.best_estimator_\n",
    "\n",
    "#Best score\n",
    "gsRFC.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7845117845117845"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##KNEIGHBORS\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "#Search grid for optimal parameters\n",
    "knn_param_grid = {\"n_neighbors\": [3,5,11,19], \"weights\": [\"uniform\", \"distance\"],\n",
    "                                                         \"metric\":[\"euclidean\", \"manhattan\"]}\n",
    "\n",
    "gsKNN = GridSearchCV(KNN, param_grid = knn_param_grid, cv = kfold, scoring = \"accuracy\",\n",
    "                    n_jobs = 1, verbose = 1)\n",
    "                                                          \n",
    "gsKNN.fit(X_train, y_train)\n",
    "    \n",
    "KNN_best = gsKNN.best_estimator_\n",
    "\n",
    "#Best score\n",
    "gsKNN.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max_features must be in (0, n_features]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a6a9aa13a5a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     n_jobs = 1, verbose = 1)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgsExtC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mExtC_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsExtC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_depth must be greater than zero. \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_features must be in (0, n_features]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n",
      "\u001b[0;31mValueError\u001b[0m: max_features must be in (0, n_features]"
     ]
    }
   ],
   "source": [
    "#EXTRA TREES\n",
    "ExtC = ExtraTreesClassifier()\n",
    "\n",
    "#Search grid for optimal parameters\n",
    "rf_param_grid = {\"max_depth\": [None], \"max_features\": [1,3,10],\n",
    "                \"min_samples_split\": [2,3,10],\n",
    "                \"min_samples_leaf\": [1,3,10],\n",
    "                \"bootstrap\": [False],\n",
    "                \"n_estimators\": [100,300],\n",
    "                \"criterion\": [\"gini\"]}\n",
    "\n",
    "gsExtC = GridSearchCV(ExtC, param_grid = rf_param_grid, cv = kfold, scoring = \"accuracy\",\n",
    "                    n_jobs = 1, verbose = 1)\n",
    "\n",
    "gsExtC.fit(X_train, y_train)\n",
    "    \n",
    "ExtC_best = gsExtC.best_estimator_\n",
    "\n",
    "#Best score\n",
    "gsExtC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADIENT BOOSTING\n",
    "\n",
    "GBC = GradientBoostingClassifier()\n",
    "\n",
    "#Search grid for optimal parameters\n",
    "rf_param_grid = {\"loss\": [\"deviance\"],\n",
    "                 \"n_estimators\": [100,200, 300, 500, 1000],\n",
    "                 \"learning_rate\": [0.1, 0.05, 0.01, 1],\n",
    "                \"max_depth\": [4, 8], \n",
    "                \"min_samples_leaf\": [100, 150],\n",
    "                 \"max_features\": [0.3, 0.1],\n",
    "                }\n",
    "\n",
    "gsGBC = GridSearchCV(GBC, param_grid = rf_param_grid, cv = kfold, scoring = \"accuracy\",\n",
    "                    n_jobs = 1, verbose = 1)\n",
    "\n",
    "gsGBC.fit(X_train, y_train)\n",
    "    \n",
    "GBC_best = gsGBC.best_estimator_\n",
    "\n",
    "#Best score\n",
    "gsGBC.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINEAR DISCRIMINANT ANALYSIS\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "grid = dict()\n",
    "grid['solver'] = ['svd', 'lsqr', 'eigen']\n",
    "\n",
    "gsLDA = GridSearchCV(LDA, grid, scoring='accuracy', cv= kfold, n_jobs=-1)\n",
    "\n",
    "gsLDA.fit(X_train, y_train)\n",
    "\n",
    "LDA_best = gsLDA.best_estimator_\n",
    "\n",
    "#Best score\n",
    "gsLDA.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADABOOST metamodel with Decision Trees\n",
    "\n",
    "# DTC = DecisionTreeClassifier()\n",
    "\n",
    "# adaDTC = AdaBoostClassifier(DTC, random_state= 7)\n",
    "\n",
    "# ada_param_grid = {\"base_estimator__criterion\": [\"gini\", \"entropy\"],\n",
    "#                  \"base_estimator__splitter\":[\"best\", \"random\"],\n",
    "#                      \"algorithm\":[\"SAMME\", \"SAMME.R\"],\n",
    "#                      \"n_estimators\": [1,2,50, 100, 500],\n",
    "#                  \"learning_rate\": [0.0001, 0.001, 0.01, 0.1,0.5,  1.0, 1.5]}\n",
    "\n",
    "# gsadaDTC = GridSearchCV(adaDTC, param_grid = ada_param_grid, cv = kfold, scoring = \"accuracy\",\n",
    "#                     n_jobs = 1, verbose = 1)\n",
    "\n",
    "# gsadaDTC.fit(X_train, y_train)\n",
    "\n",
    "# ada_best = gsadaDTC.best_estimator_\n",
    "\n",
    "# gsadaDTC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LEARNING CURVES FOR ANALYSIS OF THE ALGORITHMS\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "g = plot_learning_curve(gsRFC.best_estimator_,\"RF learning curves\",X_train,y_train,cv=kfold)\n",
    "g = plot_learning_curve(gsGBC.best_estimator_,\"GradientBoosting learning curves\",X_train,y_train,cv=kfold)\n",
    "g = plot_learning_curve(gsExtC.best_estimator_,\"ExtraTrees learning curves\",X_train,y_train,cv=kfold)\n",
    "g = plot_learning_curve(gsLDA.best_estimator_,\"LDA learning curves\",X_train,y_train,cv=kfold)\n",
    "# g = plot_learning_curve(gsadaDTC.best_estimator_,\"AdaBoost learning curves\",X_train,y_train,cv=kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FEATURE IMPORTANCE\n",
    "nrows = ncols = 2\n",
    "fig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex=\"all\", figsize=(15,15))\n",
    "\n",
    "# names_classifiers = [(\"GradientBoosting\",GBC_best),(\"AdaBoosting\", ada_best),(\"ExtraTrees\",ExtC_best),(\"RandomForest\",RFC_best), \n",
    "#                     (\"LinearDiscriminantAnalysys\",LDA_best)]\n",
    "\n",
    "names_classifiers = [(\"GradientBoosting\",GBC_best),(\"ExtraTrees\",ExtC_best),(\"RandomForest\",RFC_best), \n",
    "                    (\"LinearDiscriminantAnalysys\",LDA_best)]\n",
    "\n",
    "nclassifier = 0\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        name = names_classifiers[nclassifier][0]\n",
    "        classifier = names_classifiers[nclassifier][1]\n",
    "        indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n",
    "        g = sns.barplot(y=X_train.columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h',ax=axes[row][col])\n",
    "        g.set_xlabel(\"Relative importance\",fontsize=12)\n",
    "        g.set_ylabel(\"Features\",fontsize=12)\n",
    "        g.tick_params(labelsize=9)\n",
    "        g.set_title(name + \" feature importance\")\n",
    "        nclassifier += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###EVALUATION ON THE VALIDATION SET..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = {\"gsRFC\": gsRFC, \"gsGBC\":gsGBC, \"gsExtC\":gsExtC, \"gsLDA\":gsLDA}\n",
    "def val_scores(mods, X_val, y_val):\n",
    "    scores =pd.DataFrame(columns = [\"Model\", \"Accuracy\", \"F1_Score\"])\n",
    "    for model in mods:\n",
    "        scores = scores.append({\"Model\":model, \"Accuracy\":accuracy_score(mods[model].predict(X_val), y_val),\n",
    "                               \"F1_Score\":metrics.f1_score(mods[model].predict(X_val), y_val)},\n",
    "                               ignore_index=True )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores(mods, X_val, y_val).sort_values(by = \"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae = train.copy()\n",
    "%store mods\n",
    "%store train_mae\n",
    "%store y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2 = test_scores(mods, X_test, y_test).sort_values(by = \"Accuracy\", ascending = False).copy()\n",
    "k2.to_csv(\"k2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExtC_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Models to use\n",
    "\n",
    "RF = ensemble.RandomForestClassifier(bootstrap=False, max_features=3, min_samples_leaf=3,\n",
    "                       min_samples_split=3)\n",
    "GBC = ensemble.GradientBoostingClassifier(learning_rate=1, max_depth=4, max_features=0.1,\n",
    "                           min_samples_leaf=150, n_estimators=1000)\n",
    "ExtC = ensemble.ExtraTreesClassifier(max_features=1, min_samples_split=10, n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###SUBMITION MODULE TO KAGGLE USING THE TEST SET\n",
    "\n",
    "#Prepare test set\n",
    "out = test.pop(\"Survived\")\n",
    "test = test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a predicti0on with the selected model and feature set\n",
    "# y_pred = (0.32744636 * gsRFC.predict(test) + 0.21414157 * gsGBC.predict(test) + 0.45841208 * gsExtC.predict(test))\n",
    "RF.fit(X_train, y_train)\n",
    "GBC.fit(X_train, y_train)\n",
    "ExtC.fit(X_train, y_train)\n",
    "\n",
    "y_pred = (0.19862685* GBC.predict(test) + 0.26977291*RF.predict(test) + 0.53160024* ExtC.predict(test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###CREATE THE SUBMISSION FILE\n",
    "# Prepare Submission File\n",
    "\n",
    "%store -r test_ID\n",
    "\n",
    "submit3 = pd.DataFrame()\n",
    "submit3['PassengerId'] = test_ID\n",
    "submit3['Survived'] = y_pred\n",
    "submit3['Survived'] = submit3['Survived'].apply(lambda x:1 if x >=0.5 else 0)\n",
    "# submit = submit.set_index(\"PassengerId\")\n",
    "# ----------------------------- Create File to Submit --------------------------------\n",
    "submit3.to_csv('34_sub.csv', index = False)\n",
    "submit3.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of todays operations\n",
    "**Operations**\n",
    "0) Split train set into train and validation sets\n",
    "1) Run the models and pick the one with the lowest validation error \\\n",
    "2) I use the test set (X_val, y_val )as the evaluation of the \n",
    "(model, features set) chosen each time I make an adjustment\\\n",
    "3) Afterwards, check the feature importance and select the most relevant  features, update the dataset with them and go to (1) \n",
    "and validate in validation set \\\n",
    "4) Now I will wait and try some submissions to Kagle to evaluate using the Test Set\n",
    "\n",
    "\n",
    "Unitl now, the best performing algotihm/features tuple is: \\\n",
    "Model: gsExtC \\\n",
    "Features: (['Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Deck', 'Title'] \\\n",
    "Accuracy: 0.8101, F1: 0.7344\\\n",
    "\n",
    "Also: GB with Accuracy: 0.8045, F1: 0.7368\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texto ac\n",
    "**Ttulo en negrita\n",
    "texto\\\n",
    "para hacerlo primero se va a Markdown arriba y se elige header (con eso se genera un gran ttulo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExtC_best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5 * GBC.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
