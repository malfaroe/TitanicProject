{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from scipy.optimize import fmin\n",
    "from sklearn import metrics\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "\n",
    "\n",
    "\n",
    "class OptimizeACC:\n",
    "    \"\"\"Class for optimizing Accuracy\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0 #initialize coefficients/weights\n",
    "\n",
    "    def _acc(self, coef, X,y):\n",
    "        \"\"\"Calculates and return accuracy obtained\n",
    "        from the weighted sum of predicions\"\"\"\n",
    "        #Create predictions multiplying X tiems coefficients\n",
    "        x_coef = X * coef #pondero cada prediccion por su coef\n",
    "\n",
    "        #Create predictions by taking the sume of rows\n",
    "        predictions = np.sum(x_coef, axis = 1)  #suma ponderada da prediccion final\n",
    "        #Calculate accuracy score\n",
    "        acc_score = metrics.accuracy_score(y, predictions.round())\n",
    "\n",
    "        return -1 * acc_score #minimizaremos -acc para maximizar acc\n",
    "\n",
    "    def fit(self, X,y): #usando loss partial obtenemos los coef que minimizan -acc\n",
    "        loss_partial = partial(self._acc, X = X, y = y)\n",
    "        initial_coef = np.random.dirichlet(np.ones(X.shape[1]), size = 1)\n",
    "        self.coef_ = fmin(loss_partial, initial_coef, disp = True)\n",
    "\n",
    "    def predict(self, X):\n",
    "        x_coef = X * self.coef_\n",
    "        predictions = np.sum(x_coef, axis =1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r mods\n",
    "%store -r train_mae\n",
    "%store -r y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_mae.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gsRFC': GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "              estimator=RandomForestClassifier(), n_jobs=1,\n",
       "              param_grid={'bootstrap': [False], 'criterion': ['gini'],\n",
       "                          'max_depth': [None], 'max_features': [1, 3, 10],\n",
       "                          'min_samples_leaf': [1, 3, 10],\n",
       "                          'min_samples_split': [2, 3, 10],\n",
       "                          'n_estimators': [100, 300]},\n",
       "              scoring='accuracy', verbose=1),\n",
       " 'gsGBC': GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "              estimator=GradientBoostingClassifier(), n_jobs=1,\n",
       "              param_grid={'learning_rate': [0.1, 0.05, 0.01, 1],\n",
       "                          'loss': ['deviance'], 'max_depth': [4, 8],\n",
       "                          'max_features': [0.3, 0.1],\n",
       "                          'min_samples_leaf': [100, 150],\n",
       "                          'n_estimators': [100, 200, 300, 500, 1000]},\n",
       "              scoring='accuracy', verbose=1),\n",
       " 'gsExtC': GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "              estimator=ExtraTreesClassifier(), n_jobs=1,\n",
       "              param_grid={'bootstrap': [False], 'criterion': ['gini'],\n",
       "                          'max_depth': [None], 'max_features': [1, 3, 10],\n",
       "                          'min_samples_leaf': [1, 3, 10],\n",
       "                          'min_samples_split': [2, 3, 10],\n",
       "                          'n_estimators': [100, 300]},\n",
       "              scoring='accuracy', verbose=1),\n",
       " 'gsLDA': GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "              estimator=LinearDiscriminantAnalysis(), n_jobs=-1,\n",
       "              param_grid={'solver': ['svd', 'lsqr', 'eigen']},\n",
       "              scoring='accuracy')}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"../input/train1/train_1.csv\")\n",
    "#y = df.pop(\"Survived\")\n",
    "#X = df\n",
    "\n",
    "# X, y = make_classification(n_samples= 1000, n_features= 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a binary dataset with 10k examples and 25 features\n",
    "\n",
    "# X, y = make_classification(n_samples= 10000, n_features= 25)\n",
    "\n",
    "\n",
    "\n",
    "#Models instatiation\n",
    "# logreg = linear_model.LogisticRegression()\n",
    "# rf = ensemble.RandomForestClassifier(bootstrap=False, max_features=3, min_samples_leaf=10,\n",
    "# #                        min_samples_split=10)\n",
    "# # xgbc = xgb.XGBClassifier()\n",
    "\n",
    "# ##en este punto le puedo conectar los modelos ya entrenados con gridsearch\n",
    "\n",
    "# models = {\"logreg\":logreg, \"rf\":rf, \"xgbc\":xgbc}\n",
    "\n",
    "#Models instatiation\n",
    "rf = ensemble.RandomForestClassifier(bootstrap=False, max_features=3, min_samples_leaf=3,\n",
    "                       min_samples_split=3)\n",
    "gbc = ensemble.GradientBoostingClassifier(learning_rate=1, max_depth=4, max_features=0.1,\n",
    "                           min_samples_leaf=150, n_estimators=1000)\n",
    "xtrees = ensemble.ExtraTreesClassifier(max_features=1, min_samples_split=10, n_estimators=300)\n",
    "\n",
    "# ##en este punto le puedo conectar los modelos ya entrenados con gridsearch\n",
    "\n",
    "models = {\"xtrees\":xtrees, \"rf\":rf, \"gbc\":gbc}\n",
    "\n",
    "#Split into two folds for training/validation \n",
    "x1, x2,y1, y2 = model_selection.train_test_split(X,y, test_size = 0.5, stratify = y, random_state = 111)\n",
    "    \n",
    "\n",
    "def fold_predict(x_train, y_train,x_val, y_val, models):\n",
    "   \n",
    "    ##WORK  WITH FOLD 1\n",
    "    models_pred = [] #saves the predictions of each model\n",
    "    #Fit all models in fold1\n",
    "    for model in models:\n",
    "        models[model].fit(x_train,y_train)\n",
    "    #Take a prediction of probability on fold 2 using the fitted models\n",
    "        models_pred.append(models[model].predict_proba(x_val)[:,1])\n",
    "        \n",
    "    models_pred = np.array(models_pred).T\n",
    "    \n",
    "    #As reference, let´s take the average\n",
    "    avg_pred = np.mean(models_pred, axis = 1)\n",
    "    print(\"models_pred shape\", models_pred.shape)\n",
    "    print(\"Average shape\", avg_pred.shape)\n",
    "    \n",
    "    #Stack all predicions in a 2D array\n",
    "    y_val_pred= np.column_stack((models_pred, avg_pred))\n",
    "\n",
    "    #Aproximates the values of the prediction with threshold of 0.5\n",
    "    y_val_pred = y_val_pred.round()\n",
    "\n",
    "    #Hacemos un reporte de las accuracies\n",
    "    acc_fold = []\n",
    "    for i in range(y_val_pred.shape[1]):\n",
    "        acc = metrics.accuracy_score(y_val, y_val_pred[:,i])\n",
    "        acc_fold.append(acc)\n",
    "\n",
    "    print(f\"Fold-2: LR ACC = {acc_fold[0]}\")\n",
    "    print(f\"Fold-2: RF ACC = {acc_fold[1]}\")\n",
    "    print(f\"Fold-2: XGB ACC = {acc_fold[2]}\")\n",
    "    print(f\"Fold-2: Average Pred ACC = {acc_fold[3]}\")\n",
    "\n",
    "    return y_val_pred #returns the array of predictions for all algorithms plus the avg prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_pred shape (446, 3)\n",
      "Average shape (446,)\n",
      "Fold-2: LR ACC = 0.8139013452914798\n",
      "Fold-2: RF ACC = 0.804932735426009\n",
      "Fold-2: XGB ACC = 0.7869955156950673\n",
      "Fold-2: Average Pred ACC = 0.8004484304932735\n"
     ]
    }
   ],
   "source": [
    "y2_pred = fold_predict(x_train = x1, y_train = y1, x_val = x2, y_val = y2 , models = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_pred shape (445, 3)\n",
      "Average shape (445,)\n",
      "Fold-2: LR ACC = 0.8449438202247191\n",
      "Fold-2: RF ACC = 0.8269662921348314\n",
      "Fold-2: XGB ACC = 0.802247191011236\n",
      "Fold-2: Average Pred ACC = 0.8314606741573034\n"
     ]
    }
   ],
   "source": [
    "y1_pred = fold_predict(x_train = x2, y_train = y2, x_val = x1, y_val = y1 , models = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_coef(y1_pred, y2_pred): ##Now we find the optimal weights/coefficients to adjust using the optimizer\n",
    "    print(\"COEFFICIENTS  AND ACCURACY FOLD 1:\")\n",
    "    #Instanciamos\n",
    "    opt = OptimizeACC()\n",
    "    #Calculo los coefficientes para ajustarme a y2 usando y2_pred\n",
    "    opt.fit(y2_pred[:, :-1], y2) #me da los coeficientes que mejor maximizan la accuracy de la predicción de y2 al valor real y2\n",
    "\n",
    "    #Uso estos coeficientes pára predecir el valor de y1\n",
    "    y1_opt_predict = opt.predict(y1_pred[:,:-1])\n",
    "    # y1_opt_predict = aproximate(y1_opt_predict) #aproximo\n",
    "\n",
    "    #XCalculo el accuracy de esa predicción\n",
    "\n",
    "    acc_1 = metrics.accuracy_score(y1, y1_opt_predict.round())\n",
    "    coef_1 = np.array(opt.coef_)\n",
    "\n",
    "    #Reporte\n",
    "    print(f\"Optimized ACC, Fold 1 = {acc_1}\")\n",
    "    print(f\"Coefficients = {opt.coef_}\")\n",
    "\n",
    "    print(\"\")\n",
    "    \n",
    "    #Ahora en Fold_2\n",
    "    print(\"COEFFICIENTS  AND ACCURACY FOLD 2:\")\n",
    "    #Instanciamos\n",
    "    opt = OptimizeACC()\n",
    "    #Calculo los coefficientes para ajustarme a y1 usando y1_pred\n",
    "    opt.fit(y1_pred[:, :-1], y1) #me da los coeficientes que mejor maximizan la accuracy de la predicción de y2 al valor real y2\n",
    "\n",
    "    #Uso estos coeficientes pára predecir el valor de y1\n",
    "    y2_opt_predict = opt.predict(y2_pred[:,:-1])\n",
    "    # y2_opt_predict = aproximate(y2_opt_predict) #aproximo\n",
    "\n",
    "    #Calculo el accuracy de esa predicción\n",
    "\n",
    "    acc_2 = metrics.accuracy_score(y2, y2_opt_predict.round())\n",
    "    coef_2 = np.array(opt.coef_)\n",
    "\n",
    "    #Reporte\n",
    "    print(f\"Optimized ACC, Fold 2 = {acc_2}\")\n",
    "    print(f\"Coefficients = {opt.coef_}\")\n",
    "\n",
    "    #Averaging the coefficients\n",
    "    avg_coef = (coef_1 + coef_2) / 2\n",
    "    print(\"\")\n",
    "    print(\"Average of coefficients:\", avg_coef)\n",
    "\n",
    "    return avg_coef\n",
    "# \n",
    "#final_predict = ponderar acá. Tomar del diccionario los algorithms y ponderar el predict de test por los coeficientes model1*avg_coef[0] + ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COEFFICIENTS  AND ACCURACY FOLD 1:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.807175\n",
      "         Iterations: 9\n",
      "         Function evaluations: 44\n",
      "Optimized ACC, Fold 1 = 0.8359550561797753\n",
      "Coefficients = [0.39178346 0.24905981 0.35915673]\n",
      "\n",
      "COEFFICIENTS  AND ACCURACY FOLD 2:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.802247\n",
      "         Iterations: 10\n",
      "         Function evaluations: 49\n",
      "Optimized ACC, Fold 2 = 0.7869955156950673\n",
      "Coefficients = [0.14776237 0.14819389 0.70404375]\n",
      "\n",
      "Average of coefficients: [0.26977291 0.19862685 0.53160024]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.26977291, 0.19862685, 0.53160024])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_coef(y1_pred, y2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######CLASE INTEGRADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from scipy.optimize import fmin\n",
    "from sklearn import metrics\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "\n",
    "class OptimizeACC:\n",
    "    \"\"\"Class for optimizing Accuracy\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0 #initialize coefficients/weights\n",
    "\n",
    "    def _acc(self, coef, X,y):\n",
    "        \"\"\"Calculates and return accuracy obtained\n",
    "        from the weighted sum of predicions\"\"\"\n",
    "        #Create predictions multiplying X tiems coefficients\n",
    "        x_coef = X * coef #pondero cada prediccion por su coef\n",
    "\n",
    "        #Create predictions by taking the sume of rows\n",
    "        predictions = np.sum(x_coef, axis = 1)  #suma ponderada da prediccion final\n",
    "        #Calculate accuracy score\n",
    "        acc_score = metrics.accuracy_score(y, predictions.round())\n",
    "\n",
    "        return -1 * acc_score #minimizaremos -acc para maximizar acc\n",
    "\n",
    "    def fit(self, X,y): #usando loss partial obtenemos los coef que minimizan -acc\n",
    "        loss_partial = partial(self._acc, X = X, y = y)\n",
    "        initial_coef = np.random.dirichlet(np.ones(X.shape[1]), size = 1)\n",
    "        self.coef_ = fmin(loss_partial, initial_coef, disp = True)\n",
    "\n",
    "    def predict(self, X):\n",
    "        x_coef = X * self.coef_\n",
    "        predictions = np.sum(x_coef, axis =1)\n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def run(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a binary classification dataset with 10k samples\n",
    "# and 25 features\n",
    "X, y = make_classification(n_samples=10000, n_features=25)\n",
    "# split into two folds (for this example)\n",
    "xfold1, xfold2, yfold1, yfold2 = model_selection.train_test_split(\n",
    "X,\n",
    "y,\n",
    "test_size=0.5,\n",
    "stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-2: LR AUC = 0.964611994337919\n",
      "Fold-2: RF AUC = 0.9923053587688575\n",
      "Fold-2: XGB AUC = 0.9912477585996413\n",
      "Fold-2: Average Pred AUC = 0.9917532786805245\n",
      "Fold-1: LR AUC = 0.961189575161328\n",
      "Fold-1: RF AUC = 0.9939656761380328\n",
      "Fold-1: XGB AUC = 0.9932695956925413\n",
      "Fold-1: Average prediction AUC = 0.9926220752781282\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.994231\n",
      "         Iterations: 41\n",
      "         Function evaluations: 93\n",
      "Optimized AUC, Fold 2 = 0.9921812787490046\n",
      "Coefficients = [-0.01191033  0.70127859  0.57698455]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.992574\n",
      "         Iterations: 42\n",
      "         Function evaluations: 80\n",
      "Optimized AUC, Fold 1 = 0.9940579161970663\n",
      "Coefficients = [-0.00420418  0.04571499  0.1488837 ]\n",
      "\n",
      "Average of coefficients: [-0.00805725  0.37349679  0.36293412]\n"
     ]
    }
   ],
   "source": [
    "###codigo de abishek en libro\n",
    "\n",
    "\n",
    "class OptimizeAUC:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.coef_ = np.random.randn()\n",
    "    def _auc(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        This functions calulates and returns AUC.\n",
    "        :param coef: coef list, of the same length as number of models\n",
    "        :param X: predictions, in this case a 2d array\n",
    "        :param y: targets, in our case binary 1d array\n",
    "        \"\"\"\n",
    "        # multiply coefficients with every column of the array\n",
    "        # with predictions.\n",
    "        # this means: element 1 of coef is multiplied by column 1\n",
    "        # of the prediction array, element 2 of coef is multiplied\n",
    "        # by column 2 of the prediction array and so on!\n",
    "        x_coef = X * coef\n",
    "        # create predictions by taking row wise sum\n",
    "        predictions = np.sum(x_coef, axis=1)\n",
    "        # calculate auc score\n",
    "        auc_score = metrics.roc_auc_score(y, predictions)\n",
    "        # return negative auc\n",
    "        return -1.0 * auc_score\n",
    "    def fit(self, X, y):\n",
    "        # remember partial from hyperparameter optimization chapter?\n",
    "        loss_partial = partial(self._auc, X=X, y=y)\n",
    "        # dirichlet distribution. you can use any distribution you want\n",
    "        # to initialize the coefficients\n",
    "        # we want the coefficients to sum to 1\n",
    "        initial_coef = np.random.dirichlet(np.ones(X.shape[1]), size=1)\n",
    "        # use scipy fmin to minimize the loss function, in our case auc\n",
    "        self.coef_ = fmin(loss_partial, initial_coef, disp=True)\n",
    "    def predict(self, X):\n",
    "        # this is similar to _auc function\n",
    "        x_coef = X * self.coef_\n",
    "        predictions = np.sum(x_coef, axis=1)\n",
    "        return predictions\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "# fit models on fold 1 and make predictions on fold 2\n",
    "# we have 3 models:\n",
    "# logistic regression, random forest and xgboost\n",
    "logreg = linear_model.LogisticRegression()\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "xgbc = xgb.XGBClassifier()\n",
    "# fit all models on fold 1 data\n",
    "logreg.fit(xfold1, yfold1)\n",
    "rf.fit(xfold1, yfold1)\n",
    "xgbc.fit(xfold1, yfold1)\n",
    "# predict all models on fold 2\n",
    "# take probability for class 1\n",
    "pred_logreg = logreg.predict_proba(xfold2)[:, 1]\n",
    "pred_rf = rf.predict_proba(xfold2)[:, 1]\n",
    "pred_xgbc = xgbc.predict_proba(xfold2)[:, 1]\n",
    "\n",
    "avg_pred = (pred_logreg + pred_rf + pred_xgbc) / 3\n",
    "# a 2d array of all predictions\n",
    "fold2_preds = np.column_stack((\n",
    "pred_logreg,\n",
    "pred_rf,\n",
    "pred_xgbc,\n",
    "avg_pred\n",
    "))\n",
    "# calculate and store individual AUC values\n",
    "aucs_fold2 = []\n",
    "for i in range(fold2_preds.shape[1]):\n",
    "    auc = metrics.roc_auc_score(yfold2, fold2_preds[:, i])\n",
    "    aucs_fold2.append(auc)\n",
    "print(f\"Fold-2: LR AUC = {aucs_fold2[0]}\")\n",
    "print(f\"Fold-2: RF AUC = {aucs_fold2[1]}\")\n",
    "print(f\"Fold-2: XGB AUC = {aucs_fold2[2]}\")\n",
    "print(f\"Fold-2: Average Pred AUC = {aucs_fold2[3]}\")\n",
    "# now we repeat the same for the other fold\n",
    "# this is not the ideal way, if you ever have to repeat code,\n",
    "# create a function!\n",
    "# fit models on fold 2 and make predictions on fold 1\n",
    "logreg = linear_model.LogisticRegression()\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "xgbc = xgb.XGBClassifier()\n",
    "logreg.fit(xfold2, yfold2)\n",
    "rf.fit(xfold2, yfold2)\n",
    "xgbc.fit(xfold2, yfold2)\n",
    "pred_logreg = logreg.predict_proba(xfold1)[:, 1]\n",
    "pred_rf = rf.predict_proba(xfold1)[:, 1]\n",
    "pred_xgbc = xgbc.predict_proba(xfold1)[:, 1]\n",
    "avg_pred = (pred_logreg + pred_rf + pred_xgbc) / 3\n",
    "fold1_preds = np.column_stack((\n",
    "pred_logreg,\n",
    "pred_rf,\n",
    "pred_xgbc,\n",
    "avg_pred\n",
    "))\n",
    "aucs_fold1 = []\n",
    "for i in range(fold1_preds.shape[1]):\n",
    "    auc = metrics.roc_auc_score(yfold1, fold1_preds[:, i])\n",
    "    aucs_fold1.append(auc)\n",
    "print(f\"Fold-1: LR AUC = {aucs_fold1[0]}\")\n",
    "print(f\"Fold-1: RF AUC = {aucs_fold1[1]}\")\n",
    "print(f\"Fold-1: XGB AUC = {aucs_fold1[2]}\")\n",
    "print(f\"Fold-1: Average prediction AUC = {aucs_fold1[3]}\")\n",
    "# find optimal weights using the optimizer\n",
    "opt = OptimizeAUC()\n",
    "# dont forget to remove the average column\n",
    "opt.fit(fold1_preds[:, :-1], yfold1)\n",
    "opt_preds_fold2 = opt.predict(fold2_preds[:, :-1])\n",
    "auc = metrics.roc_auc_score(yfold2, opt_preds_fold2)\n",
    "coef_1 = np.array(opt.coef_)\n",
    "print(f\"Optimized AUC, Fold 2 = {auc}\")\n",
    "print(f\"Coefficients = {opt.coef_}\")\n",
    "opt = OptimizeAUC()\n",
    "opt.fit(fold2_preds[:, :-1], yfold2)\n",
    "opt_preds_fold1 = opt.predict(fold1_preds[:, :-1])\n",
    "auc = metrics.roc_auc_score(yfold1, opt_preds_fold1)\n",
    "coef_2 = np.array(opt.coef_)\n",
    "print(f\"Optimized AUC, Fold 1 = {auc}\")\n",
    "print(f\"Coefficients = {opt.coef_}\")\n",
    "\n",
    "\n",
    "avg_coef = (coef_1 + coef_2) / 2\n",
    "print(\"\")\n",
    "print(\"Average of coefficients:\", avg_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6667582589343684"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
