{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from scipy.optimize import fmin\n",
    "from sklearn import metrics\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "\n",
    "\n",
    "\n",
    "class OptimizeACC:\n",
    "    \"\"\"Class for optimizing Accuracy\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0 #initialize coefficients/weights\n",
    "\n",
    "    def _acc(self, coef, X,y):\n",
    "        \"\"\"Calculates and return accuracy obtained\n",
    "        from the weighted sum of predicions\"\"\"\n",
    "        #Create predictions multiplying X tiems coefficients\n",
    "        x_coef = X * coef #pondero cada prediccion por su coef\n",
    "\n",
    "        #Create predictions by taking the sume of rows\n",
    "        predictions = np.sum(x_coef, axis = 1)  #suma ponderada da prediccion final\n",
    "        #Calculate accuracy score\n",
    "        acc_score = metrics.accuracy_score(y, predictions.round())\n",
    "\n",
    "        return -1 * acc_score #minimizaremos -acc para maximizar acc\n",
    "\n",
    "    def fit(self, X,y): #usando loss partial obtenemos los coef que minimizan -acc\n",
    "        loss_partial = partial(self._acc, X = X, y = y)\n",
    "        initial_coef = np.random.dirichlet(np.ones(X.shape[1]), size = 1)\n",
    "        self.coef_ = fmin(loss_partial, initial_coef, disp = True)\n",
    "\n",
    "    def predict(self, X):\n",
    "        x_coef = X * self.coef_\n",
    "        predictions = np.sum(x_coef, axis =1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r mods\n",
    "%store -r train_mae\n",
    "%store -r y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_mae.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"../input/train1/train_1.csv\")\n",
    "#y = df.pop(\"Survived\")\n",
    "#X = df\n",
    "\n",
    "# X, y = make_classification(n_samples= 1000, n_features= 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a binary dataset with 10k examples and 25 features\n",
    "\n",
    "# X, y = make_classification(n_samples= 10000, n_features= 25)\n",
    "\n",
    "\n",
    "\n",
    "#Models instatiation\n",
    "# logreg = linear_model.LogisticRegression()\n",
    "# rf = ensemble.RandomForestClassifier(bootstrap=False, max_features=3, min_samples_leaf=10,\n",
    "# #                        min_samples_split=10)\n",
    "# # xgbc = xgb.XGBClassifier()\n",
    "\n",
    "# ##en este punto le puedo conectar los modelos ya entrenados con gridsearch\n",
    "\n",
    "# models = {\"logreg\":logreg, \"rf\":rf, \"xgbc\":xgbc}\n",
    "\n",
    "#Models instatiation\n",
    "xtrees = ensemble.ExtraTreesClassifier(max_features=3, min_samples_split=10, n_estimators=300)\n",
    "rf = ensemble.RandomForestClassifier(bootstrap=False, max_features=3, min_samples_leaf=10,\n",
    "                      min_samples_split=10)\n",
    "gbc = ensemble.GradientBoostingClassifier(learning_rate=1, max_depth=4, max_features=0.1,\n",
    "                           min_samples_leaf=150, n_estimators=300)\n",
    "\n",
    "# ##en este punto le puedo conectar los modelos ya entrenados con gridsearch\n",
    "\n",
    "models = {\"xtrees\":xtrees, \"rf\":rf, \"gbc\":gbc}\n",
    "\n",
    "#Split into two folds for training/validation \n",
    "x1, x2,y1, y2 = model_selection.train_test_split(X,y, test_size = 0.5, stratify = y, random_state = 111)\n",
    "    \n",
    "\n",
    "def fold_predict(x_train, y_train,x_val, y_val, models):\n",
    "   \n",
    "    ##WORK  WITH FOLD 1\n",
    "    models_pred = [] #saves the predictions of each model\n",
    "    #Fit all models in fold1\n",
    "    for model in models:\n",
    "        models[model].fit(x_train,y_train)\n",
    "    #Take a prediction of probability on fold 2 using the fitted models\n",
    "        models_pred.append(models[model].predict_proba(x_val)[:,1])\n",
    "        \n",
    "    models_pred = np.array(models_pred).T\n",
    "    \n",
    "    #As reference, let´s take the average\n",
    "    avg_pred = np.mean(models_pred, axis = 1)\n",
    "    print(\"models_pred shape\", models_pred.shape)\n",
    "    print(\"Average shape\", avg_pred.shape)\n",
    "    \n",
    "    #Stack all predicions in a 2D array\n",
    "    y_val_pred= np.column_stack((models_pred, avg_pred))\n",
    "\n",
    "    #Aproximates the values of the prediction with threshold of 0.5\n",
    "    y_val_pred = y_val_pred.round()\n",
    "\n",
    "    #Hacemos un reporte de las accuracies\n",
    "    acc_fold = []\n",
    "    for i in range(y_val_pred.shape[1]):\n",
    "        acc = metrics.accuracy_score(y_val, y_val_pred[:,i])\n",
    "        acc_fold.append(acc)\n",
    "\n",
    "    print(f\"Fold-2: LR ACC = {acc_fold[0]}\")\n",
    "    print(f\"Fold-2: RF ACC = {acc_fold[1]}\")\n",
    "    print(f\"Fold-2: XGB ACC = {acc_fold[2]}\")\n",
    "    print(f\"Fold-2: Average Pred ACC = {acc_fold[3]}\")\n",
    "\n",
    "    return y_val_pred #returns the array of predictions for all algorithms plus the avg prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_pred shape (446, 3)\n",
      "Average shape (446,)\n",
      "Fold-2: LR ACC = 0.8183856502242153\n",
      "Fold-2: RF ACC = 0.804932735426009\n",
      "Fold-2: XGB ACC = 0.7802690582959642\n",
      "Fold-2: Average Pred ACC = 0.7982062780269058\n"
     ]
    }
   ],
   "source": [
    "y2_pred = fold_predict(x_train = x1, y_train = y1, x_val = x2, y_val = y2 , models = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_pred shape (445, 3)\n",
      "Average shape (445,)\n",
      "Fold-2: LR ACC = 0.851685393258427\n",
      "Fold-2: RF ACC = 0.8292134831460675\n",
      "Fold-2: XGB ACC = 0.8112359550561797\n",
      "Fold-2: Average Pred ACC = 0.8314606741573034\n"
     ]
    }
   ],
   "source": [
    "y1_pred = fold_predict(x_train = x2, y_train = y2, x_val = x1, y_val = y1 , models = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_coef(y1_pred, y2_pred): ##Now we find the optimal weights/coefficients to adjust using the optimizer\n",
    "    print(\"COEFFICIENTS  AND ACCURACY FOLD 1:\")\n",
    "    #Instanciamos\n",
    "    opt = OptimizeACC()\n",
    "    #Calculo los coefficientes para ajustarme a y2 usando y2_pred\n",
    "    opt.fit(y2_pred[:, :-1], y2) #me da los coeficientes que mejor maximizan la accuracy de la predicción de y2 al valor real y2\n",
    "\n",
    "    #Uso estos coeficientes pára predecir el valor de y1\n",
    "    y1_opt_predict = opt.predict(y1_pred[:,:-1])\n",
    "    # y1_opt_predict = aproximate(y1_opt_predict) #aproximo\n",
    "\n",
    "    #XCalculo el accuracy de esa predicción\n",
    "\n",
    "    acc_1 = metrics.accuracy_score(y1, y1_opt_predict.round())\n",
    "    coef_1 = np.array(opt.coef_)\n",
    "\n",
    "    #Reporte\n",
    "    print(f\"Optimized ACC, Fold 1 = {acc_1}\")\n",
    "    print(f\"Coefficients = {opt.coef_}\")\n",
    "\n",
    "    print(\"\")\n",
    "    \n",
    "    #Ahora en Fold_2\n",
    "    print(\"COEFFICIENTS  AND ACCURACY FOLD 2:\")\n",
    "    #Instanciamos\n",
    "    opt = OptimizeACC()\n",
    "    #Calculo los coefficientes para ajustarme a y1 usando y1_pred\n",
    "    opt.fit(y1_pred[:, :-1], y1) #me da los coeficientes que mejor maximizan la accuracy de la predicción de y2 al valor real y2\n",
    "\n",
    "    #Uso estos coeficientes pára predecir el valor de y1\n",
    "    y2_opt_predict = opt.predict(y2_pred[:,:-1])\n",
    "    # y2_opt_predict = aproximate(y2_opt_predict) #aproximo\n",
    "\n",
    "    #Calculo el accuracy de esa predicción\n",
    "\n",
    "    acc_2 = metrics.accuracy_score(y2, y2_opt_predict.round())\n",
    "    coef_2 = np.array(opt.coef_)\n",
    "\n",
    "    #Reporte\n",
    "    print(f\"Optimized ACC, Fold 2 = {acc_2}\")\n",
    "    print(f\"Coefficients = {opt.coef_}\")\n",
    "\n",
    "    #Averaging the coefficients\n",
    "    avg_coef = (coef_1 + coef_2) / 2\n",
    "    print(\"\")\n",
    "    print(\"Average of coefficients:\", avg_coef)\n",
    "\n",
    "    return avg_coef\n",
    "# \n",
    "#final_predict = ponderar acá. Tomar del diccionario los algorithms y ponderar el predict de test por los coeficientes model1*avg_coef[0] + ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COEFFICIENTS  AND ACCURACY FOLD 1:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.818386\n",
      "         Iterations: 10\n",
      "         Function evaluations: 49\n",
      "Optimized ACC, Fold 1 = 0.851685393258427\n",
      "Coefficients = [0.7088383  0.11926655 0.17189515]\n",
      "\n",
      "COEFFICIENTS  AND ACCURACY FOLD 2:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.811236\n",
      "         Iterations: 10\n",
      "         Function evaluations: 49\n",
      "Optimized ACC, Fold 2 = 0.7802690582959642\n",
      "Coefficients = [0.06956534 0.23325212 0.69718254]\n",
      "\n",
      "Average of coefficients: [0.38920182 0.17625934 0.43453884]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.38920182, 0.17625934, 0.43453884])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_coef(y1_pred, y2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######CLASE INTEGRADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from scipy.optimize import fmin\n",
    "from sklearn import metrics\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "\n",
    "class OptimizeACC:\n",
    "    \"\"\"Class for optimizing Accuracy\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0 #initialize coefficients/weights\n",
    "\n",
    "    def _acc(self, coef, X,y):\n",
    "        \"\"\"Calculates and return accuracy obtained\n",
    "        from the weighted sum of predicions\"\"\"\n",
    "        #Create predictions multiplying X tiems coefficients\n",
    "        x_coef = X * coef #pondero cada prediccion por su coef\n",
    "\n",
    "        #Create predictions by taking the sume of rows\n",
    "        predictions = np.sum(x_coef, axis = 1)  #suma ponderada da prediccion final\n",
    "        #Calculate accuracy score\n",
    "        acc_score = metrics.accuracy_score(y, predictions.round())\n",
    "\n",
    "        return -1 * acc_score #minimizaremos -acc para maximizar acc\n",
    "\n",
    "    def fit(self, X,y): #usando loss partial obtenemos los coef que minimizan -acc\n",
    "        loss_partial = partial(self._acc, X = X, y = y)\n",
    "        initial_coef = np.random.dirichlet(np.ones(X.shape[1]), size = 1)\n",
    "        self.coef_ = fmin(loss_partial, initial_coef, disp = True)\n",
    "\n",
    "    def predict(self, X):\n",
    "        x_coef = X * self.coef_\n",
    "        predictions = np.sum(x_coef, axis =1)\n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def run(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-2: LR AUC = 0.9441915885218665\n",
      "Fold-2: RF AUC = 0.9468198554353195\n",
      "Fold-2: XGB AUC = 0.9408069138627979\n",
      "Fold-2: Average Pred AUC = 0.9487009146973664\n",
      "Fold-1: LR AUC = 0.9443930305846331\n",
      "Fold-1: RF AUC = 0.9466840940451231\n",
      "Fold-1: XGB AUC = 0.9441912685185898\n",
      "Fold-1: Average prediction AUC = 0.9485255529016617\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.948701\n",
      "         Iterations: 31\n",
      "         Function evaluations: 70\n",
      "Optimized AUC, Fold 2 = 0.9489701974548221\n",
      "Coefficients = [0.25541658 0.28675188 0.13679006]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.948984\n",
      "         Iterations: 40\n",
      "         Function evaluations: 83\n",
      "Optimized AUC, Fold 1 = 0.9486837945220559\n",
      "Coefficients = [0.22347888 0.25355418 0.10259673]\n",
      "\n",
      "Average of coefficients: [0.23944773 0.27015303 0.11969339]\n"
     ]
    }
   ],
   "source": [
    "class OptimizeAUC:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "    def _auc(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        This functions calulates and returns AUC.\n",
    "        :param coef: coef list, of the same length as number of models\n",
    "        :param X: predictions, in this case a 2d array\n",
    "        :param y: targets, in our case binary 1d array\n",
    "        \"\"\"\n",
    "        # multiply coefficients with every column of the array\n",
    "        # with predictions.\n",
    "        # this means: element 1 of coef is multiplied by column 1\n",
    "        # of the prediction array, element 2 of coef is multiplied\n",
    "        # by column 2 of the prediction array and so on!\n",
    "        x_coef = X * coef\n",
    "        # create predictions by taking row wise sum\n",
    "        predictions = np.sum(x_coef, axis=1)\n",
    "        # calculate auc score\n",
    "        auc_score = metrics.roc_auc_score(y, predictions)\n",
    "        # return negative auc\n",
    "        return -1.0 * auc_score\n",
    "    def fit(self, X, y):\n",
    "        # remember partial from hyperparameter optimization chapter?\n",
    "        loss_partial = partial(self._auc, X=X, y=y)\n",
    "        # dirichlet distribution. you can use any distribution you want\n",
    "        # to initialize the coefficients\n",
    "        # we want the coefficients to sum to 1\n",
    "        initial_coef = np.random.dirichlet(np.ones(X.shape[1]), size=1)\n",
    "        # use scipy fmin to minimize the loss function, in our case auc\n",
    "        self.coef_ = fmin(loss_partial, initial_coef, disp=True)\n",
    "    def predict(self, X):\n",
    "        # this is similar to _auc function\n",
    "        x_coef = X * self.coef_\n",
    "        predictions = np.sum(x_coef, axis=1)\n",
    "        return predictions\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "# make a binary classification dataset with 10k samples\n",
    "# and 25 features\n",
    "X, y = make_classification(n_samples=10000, n_features=25)\n",
    "# split into two folds (for this example)\n",
    "xfold1, xfold2, yfold1, yfold2 = model_selection.train_test_split(\n",
    "X,\n",
    "y,\n",
    "test_size=0.5,\n",
    "stratify=y\n",
    ")\n",
    "# fit models on fold 1 and make predictions on fold 2\n",
    "# we have 3 models:\n",
    "# logistic regression, random forest and xgboost\n",
    "logreg = linear_model.LogisticRegression()\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "xgbc = xgb.XGBClassifier()\n",
    "# fit all models on fold 1 data\n",
    "logreg.fit(xfold1, yfold1)\n",
    "rf.fit(xfold1, yfold1)\n",
    "xgbc.fit(xfold1, yfold1)\n",
    "# predict all models on fold 2\n",
    "# take probability for class 1\n",
    "pred_logreg = logreg.predict_proba(xfold2)[:, 1]\n",
    "pred_rf = rf.predict_proba(xfold2)[:, 1]\n",
    "pred_xgbc = xgbc.predict_proba(xfold2)[:, 1]\n",
    "\n",
    "avg_pred = (pred_logreg + pred_rf + pred_xgbc) / 3\n",
    "# a 2d array of all predictions\n",
    "fold2_preds = np.column_stack((\n",
    "pred_logreg,\n",
    "pred_rf,\n",
    "pred_xgbc,\n",
    "avg_pred\n",
    "))\n",
    "# calculate and store individual AUC values\n",
    "aucs_fold2 = []\n",
    "for i in range(fold2_preds.shape[1]):\n",
    "    auc = metrics.roc_auc_score(yfold2, fold2_preds[:, i])\n",
    "    aucs_fold2.append(auc)\n",
    "print(f\"Fold-2: LR AUC = {aucs_fold2[0]}\")\n",
    "print(f\"Fold-2: RF AUC = {aucs_fold2[1]}\")\n",
    "print(f\"Fold-2: XGB AUC = {aucs_fold2[2]}\")\n",
    "print(f\"Fold-2: Average Pred AUC = {aucs_fold2[3]}\")\n",
    "# now we repeat the same for the other fold\n",
    "# this is not the ideal way, if you ever have to repeat code,\n",
    "# create a function!\n",
    "# fit models on fold 2 and make predictions on fold 1\n",
    "logreg = linear_model.LogisticRegression()\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "xgbc = xgb.XGBClassifier()\n",
    "logreg.fit(xfold2, yfold2)\n",
    "rf.fit(xfold2, yfold2)\n",
    "xgbc.fit(xfold2, yfold2)\n",
    "pred_logreg = logreg.predict_proba(xfold1)[:, 1]\n",
    "pred_rf = rf.predict_proba(xfold1)[:, 1]\n",
    "pred_xgbc = xgbc.predict_proba(xfold1)[:, 1]\n",
    "avg_pred = (pred_logreg + pred_rf + pred_xgbc) / 3\n",
    "fold1_preds = np.column_stack((\n",
    "pred_logreg,\n",
    "pred_rf,\n",
    "pred_xgbc,\n",
    "avg_pred\n",
    "))\n",
    "aucs_fold1 = []\n",
    "for i in range(fold1_preds.shape[1]):\n",
    "    auc = metrics.roc_auc_score(yfold1, fold1_preds[:, i])\n",
    "    aucs_fold1.append(auc)\n",
    "print(f\"Fold-1: LR AUC = {aucs_fold1[0]}\")\n",
    "print(f\"Fold-1: RF AUC = {aucs_fold1[1]}\")\n",
    "print(f\"Fold-1: XGB AUC = {aucs_fold1[2]}\")\n",
    "print(f\"Fold-1: Average prediction AUC = {aucs_fold1[3]}\")\n",
    "# find optimal weights using the optimizer\n",
    "opt = OptimizeAUC()\n",
    "# dont forget to remove the average column\n",
    "opt.fit(fold1_preds[:, :-1], yfold1)\n",
    "opt_preds_fold2 = opt.predict(fold2_preds[:, :-1])\n",
    "auc = metrics.roc_auc_score(yfold2, opt_preds_fold2)\n",
    "coef_1 = np.array(opt.coef_)\n",
    "print(f\"Optimized AUC, Fold 2 = {auc}\")\n",
    "print(f\"Coefficients = {opt.coef_}\")\n",
    "opt = OptimizeAUC()\n",
    "opt.fit(fold2_preds[:, :-1], yfold2)\n",
    "opt_preds_fold1 = opt.predict(fold1_preds[:, :-1])\n",
    "auc = metrics.roc_auc_score(yfold1, opt_preds_fold1)\n",
    "coef_2 = np.array(opt.coef_)\n",
    "print(f\"Optimized AUC, Fold 1 = {auc}\")\n",
    "print(f\"Coefficients = {opt.coef_}\")\n",
    "\n",
    "\n",
    "avg_coef = (coef_1 + coef_2) / 2\n",
    "print(\"\")\n",
    "print(\"Average of coefficients:\", avg_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
