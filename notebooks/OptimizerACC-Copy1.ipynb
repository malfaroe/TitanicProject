{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from scipy.optimize import fmin\n",
    "from sklearn import metrics\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizeACC:\n",
    "    \"\"\"Class for optimizing Accuracy: computes the optimal coefficients/weights for\n",
    "    ensemble model predictions\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.coef_ = 1 #initialize coefficients/weights\n",
    "\n",
    "    def _acc(self, coef, X,y):\n",
    "        \"\"\"Calculates and return accuracy obtained\n",
    "        from the weighted sum of predicions\"\"\"\n",
    "        #Create predictions multiplying X tiems coefficients\n",
    "        x_coef = X * coef #pondero cada prediccion por su coef\n",
    "\n",
    "        #Create predictions by taking the sume of rows\n",
    "        predictions = np.sum(x_coef, axis = 1)  #suma ponderada da prediccion final\n",
    "        #Calculate accuracy score\n",
    "        acc_score = metrics.accuracy_score(y, predictions.round())\n",
    "\n",
    "        return -1 * acc_score #minimizaremos -acc para maximizar acc\n",
    "\n",
    "    def fit(self, X,y): #usando loss partial obtenemos los coef que minimizan -acc\n",
    "        loss_partial = partial(self._acc, X = X, y = y)\n",
    "        initial_coef = np.random.dirichlet(np.ones(X.shape[1]), size = 1)\n",
    "        self.coef_ = fmin(loss_partial, initial_coef, disp = True)\n",
    "        return self.coef_\n",
    "\n",
    "    def predict(self, X):\n",
    "        x_coef = X * self.coef_\n",
    "        predictions = np.sum(x_coef, axis =1)\n",
    "        return predictions\n",
    "        \n",
    "    def fold_predict(self, x_train, y_train,x_val, y_val, models):\n",
    "        models_pred = [] #saves the predictions of each model\n",
    "        #Fit all models in fold1\n",
    "        for model in models:\n",
    "            models[model].fit(x_train,y_train)\n",
    "        #Take a prediction of probability on fold 2 using the fitted models\n",
    "            models_pred.append(models[model].predict_proba(x_val)[:,1])\n",
    "\n",
    "        models_pred = np.array(models_pred).T\n",
    "\n",
    "        #As reference, let´s take the average\n",
    "        avg_pred = np.mean(models_pred, axis = 1)\n",
    "\n",
    "        #Stack all predicions in a 2D array\n",
    "        y_val_pred= np.column_stack((models_pred, avg_pred))\n",
    "\n",
    "        #Aproximates the values of the prediction with threshold of 0.5\n",
    "        y_val_pred = y_val_pred.round()\n",
    "\n",
    "        #Hacemos un reporte de las accuracies\n",
    "        acc_fold = []\n",
    "        for i in range(y_val_pred.shape[1]):\n",
    "            acc = metrics.accuracy_score(y_val, y_val_pred[:,i])\n",
    "            acc_fold.append(acc)\n",
    "\n",
    "        print(f\"Fold: LR ACC = {acc_fold[0]}\")\n",
    "        print(f\"Fold: RF ACC = {acc_fold[1]}\")\n",
    "        print(f\"Fold: XGB ACC = {acc_fold[2]}\")\n",
    "        print(f\"Fold: Average Pred ACC = {acc_fold[3]}\")\n",
    "\n",
    "        return y_val_pred #returns the array of predictions for all algorithms plus the avg prediction\n",
    "    \n",
    "    def opt_coef(self, y1_pred, y2_pred): ##Now we find the optimal weights/coefficients to adjust using the optimizer\n",
    "        print(\"COEFFICIENTS  AND ACCURACY FOLD 1:\")\n",
    "        \n",
    "        #Calculo los coefficientes para ajustarme a y2 usando y2_pred\n",
    "        coef_1= self.fit(y2_pred[:, :-1], y2) #me da los coeficientes que mejor maximizan la accuracy de la predicción de y2 al valor real y2\n",
    "\n",
    "        #Uso estos coeficientes pára predecir el valor de y1\n",
    "        y1_opt_predict = self.predict(y1_pred[:,:-1])\n",
    "\n",
    "        #XCalculo el accuracy de esa predicción\n",
    "\n",
    "        acc_1 = metrics.accuracy_score(y1, y1_opt_predict.round())\n",
    "        coef_1 = np.array(coef_1)\n",
    "\n",
    "        #Reporte\n",
    "        print(f\"Optimized ACC, Fold 1 = {acc_1}\")\n",
    "        print(f\"Coefficients = {coef_1}\")\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "        #Ahora en Fold_2\n",
    "        print(\"COEFFICIENTS  AND ACCURACY FOLD 2:\")\n",
    "        #Calculo los coefficientes para ajustarme a y1 usando y1_pred\n",
    "        coef_2 = self.fit(y1_pred[:, :-1], y1) #me da los coeficientes que mejor maximizan la accuracy de la predicción de y2 al valor real y2\n",
    "\n",
    "        #Uso estos coeficientes pára predecir el valor de y1\n",
    "        y2_opt_predict = self.predict(y2_pred[:,:-1])\n",
    "\n",
    "        #Calculo el accuracy de esa predicción\n",
    "\n",
    "        acc_2 = metrics.accuracy_score(y2, y2_opt_predict.round())\n",
    "        coef_2 = np.array(coef_2)\n",
    "\n",
    "        #Reporte\n",
    "        print(f\"Optimized ACC, Fold 2 = {acc_2}\")\n",
    "        print(f\"Coefficients = {coef_2}\")\n",
    "\n",
    "        #Averaging the coefficients\n",
    "        avg_coef = (coef_1 + coef_2) / 2\n",
    "        print(\"\")\n",
    "        print(\"Average of coefficients:\", avg_coef)\n",
    "\n",
    "        return avg_coef\n",
    "    \n",
    "    def run(self, X, y, models):# recibe X,y, diccionario de modelos ya instanciados\n",
    "        #Split into two folds for training/validation \n",
    "        x1, x2,y1, y2 = model_selection.train_test_split(X,y, test_size = 0.5, stratify = y, random_state = 42)\n",
    "        y2_p = self.fold_predict(x_train = x1, y_train = y1, x_val = x2, y_val = y2 , models = models)\n",
    "        y1_p = self.fold_predict(x_train = x2, y_train = y2, x_val = x1, y_val = y1 , models = models)\n",
    "        coef = self.opt_coef(y1_p,y2_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WITH RUN METHOD:\n",
      "Fold: LR ACC = 0.8528\n",
      "Fold: RF ACC = 0.8614\n",
      "Fold: XGB ACC = 0.8508\n",
      "Fold: Average Pred ACC = 0.8598\n",
      "Fold: LR ACC = 0.847\n",
      "Fold: RF ACC = 0.8594\n",
      "Fold: XGB ACC = 0.8496\n",
      "Fold: Average Pred ACC = 0.8564\n",
      "COEFFICIENTS  AND ACCURACY FOLD 1:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.859600\n",
      "         Iterations: 9\n",
      "         Function evaluations: 44\n",
      "Optimized ACC, Fold 1 = 0.8574\n",
      "Coefficients = [0.2037062  0.40574453 0.39054926]\n",
      "\n",
      "COEFFICIENTS  AND ACCURACY FOLD 2:\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.857400\n",
      "         Iterations: 9\n",
      "         Function evaluations: 44\n",
      "Optimized ACC, Fold 2 = 0.8596\n",
      "Coefficients = [0.34378226 0.35208292 0.30413482]\n",
      "\n",
      "Average of coefficients: [0.27374423 0.37891373 0.34734204]\n"
     ]
    }
   ],
   "source": [
    "##Testing zone\n",
    "\n",
    "# from sklearn.datasets import load_iris\n",
    "# iris = load_iris()\n",
    "# y = iris.target\n",
    "# X = iris.data\n",
    "X, y = make_classification(n_samples= 10000, n_features= 25)\n",
    "\n",
    "\n",
    "#Models\n",
    "# logistic regression, random forest and xgboost\n",
    "logreg = linear_model.LogisticRegression()\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "xgbc = xgb.XGBClassifier()\n",
    "\n",
    "models = {\"logreg\":logreg, \"rf\":rf, \"xgbc\":xgbc}\n",
    "\n",
    "#Split into two folds for training/validation \n",
    "x1, x2,y1, y2 = model_selection.train_test_split(X,y, test_size = 0.5, stratify = y, random_state = 42)\n",
    "\n",
    "\n",
    "ot = OptimizeACC()\n",
    "# ot.run(X,y, models)\n",
    "# y2_p = ot.fold_predict(x_train = x1, y_train = y1, x_val = x2, y_val = y2 , models = models)\n",
    "# y1_p = ot.fold_predict(x_train = x2, y_train = y2, x_val = x1, y_val = y1 , models = models)\n",
    "# coef = ot.opt_coef(y1_p,y2_p)\n",
    "\n",
    "print(\"\")\n",
    "print(\"WITH RUN METHOD:\")\n",
    "ot.run(X,y, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT:Convertir ahora a un módulo importable desde cualquier otro código:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
